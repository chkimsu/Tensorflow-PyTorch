{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import Tensor, nn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Boston 집값 데이터를 읽어온다.\n",
    "X, y = load_boston(return_X_y=True)\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "class SklearnDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        super().__init__()\n",
    "        scaler = MinMaxScaler() \n",
    "\n",
    "        scaler.fit(X) \n",
    "        self.X = scaler.transform(X)\n",
    "        self.Y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].astype(np.float32)\n",
    "        y = self.Y[idx].astype(np.float32)\n",
    "        return x, y\n",
    "\n",
    "train_Dataset = SklearnDataset(train_x, train_y)\n",
    "valid_Dataset = SklearnDataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1068], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(13, 1, bias=True)\n",
    "model(torch.Tensor(train_Dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name   | Type   | Params\n",
      "----------------------------------\n",
      "0 | linear | Linear | 14    \n",
      "----------------------------------\n",
      "14        Trainable params\n",
      "0         Non-trainable params\n",
      "14        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 15/15 [00:00<00:00, 140.19it/s, loss=5.87e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mse improved. New best score: 598.572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 15/15 [00:00<00:00, 130.44it/s, loss=5.87e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: val_mse reached 598.57214 (best 598.57214), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=0-step=10-v1.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 137.79it/s, loss=5.92e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 21: val_mse reached 611.67932 (best 598.57214), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=1-step=21.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 120.00it/s, loss=5.81e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 32: val_mse reached 623.51428 (best 598.57214), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=2-step=32-v1.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 159.57it/s, loss=5.85e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mse improved by 5.581 >= min_delta = 0.0. New best score: 592.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 145.63it/s, loss=5.85e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 43: val_mse reached 592.99084 (best 592.99084), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=3-step=43-v1.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 161.39it/s, loss=5.75e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mse improved by 5.055 >= min_delta = 0.0. New best score: 587.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 147.14it/s, loss=5.75e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 54: val_mse reached 587.93536 (best 587.93536), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=4-step=54.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 183.02it/s, loss=5.78e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mse improved by 0.820 >= min_delta = 0.0. New best score: 587.115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 170.49it/s, loss=5.78e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 65: val_mse reached 587.11493 (best 587.11493), saving model to \"c:\\Users\\chkim\\OneDrive\\바탕 화면\\Study\\checkpoints\\epoch=5-step=65.ckpt\" as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 142.20it/s, loss=5.8e+05, v_num=6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 76: val_mse was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 139.56it/s, loss=5.79e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 87: val_mse was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 140.20it/s, loss=5.68e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mse did not improve in the last 3 records. Best score: 587.115. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 132.75it/s, loss=5.68e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 98: val_mse was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 126.91it/s, loss=5.68e+05, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_Dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_Dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "class LinRegModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=13, out_features=1, bias=True)\n",
    "        self.batch_size = 32\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_hat = self.linear(x)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # flatten any input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction=\"sum\")\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self(x)\n",
    "        mse = F.mse_loss(logits, y)\n",
    "        metrics = {'val_mse': mse}\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            max_lr=1e-3,\n",
    "            epochs=10,\n",
    "            optimizer=optimizer,\n",
    "            steps_per_epoch=int(len(train_Dataset) / self.batch_size),\n",
    "            pct_start=0.1,\n",
    "            div_factor=10,\n",
    "            final_div_factor=100,\n",
    "            base_momentum=0.90,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    verbose=True,\n",
    "    save_last=True,\n",
    "    save_top_k= 3,\n",
    "    monitor='val_mse',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mse',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# training\n",
    "trainer_args = {\n",
    "    'callbacks': [checkpoint_callback, early_stopping],\n",
    "    'max_epochs' : 30\n",
    "}\n",
    "\n",
    "trainer = pl.Trainer(**trainer_args)\n",
    "model = LinRegModel(13)\n",
    "trainer.fit(model, train_loader, valid_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "              precision=16,                    # Double precision (64), full precision (32) or half precision (16)\n",
    "                               # Distributed_backend (dp, ddp, etc ...)\n",
    "              #gpus=4,                          # GPU 개수\n",
    "              accumulate_grad_batches=1,       # Gradient를 몇 개의 배치동안 누적해서 계산할 것인지\n",
    "              #amp_backend=\"apex\",              # mixed precision backend to use (“native” or “apex”)\n",
    "              auto_select_gpus=True,           # 사용가능한 GPU를 알아서 잡아준다.\n",
    "              check_val_every_n_epoch=1,       # 몇 개의 epoch마다 validation 할 것 인지\n",
    "              gradient_clip_val=5.0,           # Gradient clipping을 얼마로 할 것인지\n",
    "               # 로그 선택\n",
    "              auto_scale_batch_size=\"binsearch\",                    # 메모리에 적합한 가장 큰 배치 사이즈를 찾아준다.\n",
    "              max_epochs=20,                                        # 최대 epoch 수\n",
    ")\n",
    "\n",
    "model = LinRegModel(input_dim=13)\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a76ec67cc700e8b4b69919c38150e027361854285467e972b878ad1dc6c1f25"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('graph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
